{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMINAR_PATH = '/home/jim/PycharmProjects'\n",
    "\n",
    "import sys\n",
    "sys.path.append(SEMINAR_PATH)\n",
    "\n",
    "import seminar\n",
    "from seminar.learn.cnn_lstm import convlstm, convgru\n",
    "from seminar.learn.cnn import LSTM, LSTM2, CNN\n",
    "from seminar.utils import BiDict\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "#import dill as pickle\n",
    "#import pathos.multiprocessing as multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'seminar.learn.cnn' from '/home/jim/PycharmProjects/seminar/learn/cnn.py'>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(seminar.learn.cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = '/home/jim/mount/shared/course/geo441/stud/B_Camargue/assembled_datasets/patches/spv__15x15__s1_s2_s2inds_visnirtex_unnorm/trn'\n",
    "val = '/home/jim/mount/shared/course/geo441/stud/B_Camargue/assembled_datasets/patches/spv__15x15__s1_s2_s2inds_visnirtex_unnorm/val'\n",
    "\n",
    "#trn = '/home/jim/PycharmProjects/seminar/notebooks/data/spv__17x17__f32__nofilt__nearest_time_upsampled/trn'\n",
    "#val = '/home/jim/PycharmProjects/seminar/notebooks/data/spv__17x17__f32__nofilt__nearest_time_upsampled/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(list(map(int, [x[1] for x in os.walk(trn)][0] + [x[1] for x in os.walk(val)][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1110, 1121, 1122, 1124, 1131, 1132, 1133, 1210, 1230, 1310, 1320,\n",
       "       1330, 1411, 1412, 1413, 1415, 1420, 2111, 2112, 2113, 2114, 2115,\n",
       "       2120, 2131, 2132, 2140, 2210, 2220, 2310, 3110, 3121, 3122, 3123,\n",
       "       3211, 3212, 3220, 3310, 3321, 3322, 3323, 4111, 4112, 4113, 4121,\n",
       "       4122, 4131, 4132, 4133, 4211, 4212, 4220, 5120, 5210])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Reader and Test It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader(path, with_cloud_mask=False):\n",
    "    patch = np.load(path)\n",
    "\n",
    "    # s1 bands\n",
    "    rang = np.array([-20, 5])\n",
    "    patch[:, :2, :, :] = np.clip((patch[:, :2, :, :] - rang.mean()) / (rang[1] - rang[0]), -1, 1)\n",
    "    \n",
    "    # opt bands\n",
    "    rang = np.array([0, 10000])\n",
    "    patch[:, 2:12, :, :] = np.clip((patch[:, 2:12, :, :] - rang.mean()) / (rang[1] - rang[0]), -1, 1)\n",
    "    \n",
    "    # index evi\n",
    "    rang = np.array([-20000, 20000])\n",
    "    patch[:, 12, :, :] = (patch[:, 13, :, :] - rang.mean()) / (rang[1] - rang[0])\n",
    "    \n",
    "    nan_val = (-3e4  - rang.mean()) / (rang[1] - rang[0])\n",
    "    valid_inds = np.where(patch[:, 12, :, :] > nan_val)\n",
    "    patch[:, 12, :, :][valid_inds] = np.clip(patch[:, 12, :, :][valid_inds], -1, 1)\n",
    "    \n",
    "    # other index bands\n",
    "    rang = np.array([-10000, 10000])\n",
    "    patch[:, 13:18, :, :] = (patch[:, 13:18, :, :] - rang.mean()) / (rang[1] - rang[0])\n",
    "    \n",
    "    nan_val = (-3e4  - rang.mean()) / (rang[1] - rang[0])\n",
    "    valid_inds = np.where(patch[:, 13:18, :, :] > nan_val)\n",
    "    patch[:, 13:18, :, :][valid_inds] = np.clip(patch[:, 13:18, :, :][valid_inds], -1, 1)\n",
    "    \n",
    "    # tex bands\n",
    "    rang = np.array([-100, 100])\n",
    "    patch[:, 18:68, :, :] = np.clip((patch[:, 18:68, :, :] - rang.mean()) / (rang[1] - rang[0]), -1, 1)\n",
    "    \n",
    "    # add a cloud layer\n",
    "    if with_cloud_mask:\n",
    "        # use some index but not EVI\n",
    "        clouds = (patch[:, 13, :, :] < nan_val).astype(np.int)[:, None, :, :]\n",
    "        patch = np.concatenate([patch, clouds], axis=1)\n",
    "    \n",
    "    patch = np.concatenate([patch[:, :2], patch[:, 12:]], axis=1)\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_path = '/home/jim/mount/shared/course/geo441/stud/B_Camargue/assembled_datasets/patches/spv__15x15__s1_s2_s2inds_visnirtex_unnorm/trn/2115/1010_1397_1025_1412.npy'#\n",
    "#sample_image_path = '/home/jim/PycharmProjects/seminar/notebooks/data/spv__17x17__f32__nofilt__nearest_time_upsampled/trn/1121/370_1646_383_1659.npy'\n",
    "sample_image = np.load(sample_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 69, 15, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_image_path2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ea71763e201d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_image_path2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_cloud_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_image_path2' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = 12\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(reader(sample_image_path2, with_cloud_mask=True)[time,0])\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(reader(sample_image_path2, with_cloud_mask=True)[time,0].flatten())\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(reader(sample_image_path2, with_cloud_mask=True)[time,2])\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(reader(sample_image_path2, with_cloud_mask=True)[time,2].flatten())\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(reader(sample_image_path2, with_cloud_mask=True)[time,3])\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(reader(sample_image_path2, with_cloud_mask=True)[time,3].flatten())\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(reader(sample_image_path2, with_cloud_mask=True)[time,-1])\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(reader(sample_image_path2, with_cloud_mask=True)[time,-1].flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'lstm__lay_10_10_dset_all__weigths_eq__reduce_channels8'\n",
    "default_save_path = '/home/jim/PycharmProjects/seminar/notebooks/lightning_logs/' + run_name + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath= default_save_path + 'checkpoints/{epoch}-{val_loss:.2f}',\n",
    "    save_top_k=5,\n",
    "    verbose=True,\n",
    "    monitor='f1/d1/4',\n",
    "    mode='max',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = np.array([[1, 0.3, 0.2, 0.1, 0.01],\n",
    "                    [1, 0.3, 0.2, 0.1, 0.01],\n",
    "                    [1, 0.3, 0.2, 0.1, 0.01],\n",
    "                    [1, 0.3, 0.2, 0.1, 0.01],\n",
    "                    [1, 0.3, 0.2, 0.1, 0.01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2 = np.array([[1, 1, 1, 1, 1]]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights22 = np.array([[1, 1, 1, 1, 1],\n",
    "                     [1, 1, 1, 1, 1],\n",
    "                     [1, 1, 1, 1, 1],\n",
    "                     [1, 1, 1, 1, 1],\n",
    "                     [1, 1, 1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(in_channels=sample_image.shape[1] + 1 - 10,\n",
    "            num_layers=3, hidden_channels=[5, 5, 1], \n",
    "            kernel_size=[(3, 3), (3, 3), (3, 3)],#, (3, 3), (3, 3)],\n",
    "            train_image_folder=trn,\n",
    "            val_image_folder=val,\n",
    "            hierarchy_weights=weights22, seq_len=sample_image.shape[0],\n",
    "            reduce_hidden=1, reduce_channels=16,\n",
    "            n_jobs=6, batch_size=32, input_shape=sample_image[0, 0].shape, epoch_size=None, stratified_input=True, reader=partial(reader, with_cloud_mask=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm2 = LSTM2(input_shape=sample_image.shape[1:], hidden_size=100, embed_size=100, in_channels=sample_image.shape[1] + 1 - 10,\n",
    "              train_image_folder=trn, val_image_folder=val, n_jobs=3, drop_rate=0.3, bn_momentum=0.9, bn_track_running_stats=False,\n",
    "              channels=[30, 30], batch_size=32, seq_len=sample_image.shape[0], epoch_size=None, lr=1e-4, \n",
    "              hierarchy_weights=weights1, kernel_size=3, reduce_kernel_size=11, reduce_hidden=1, reduce_channels=8, \n",
    "              stratified_input=True, reader=partial(reader, with_cloud_mask=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(input_shape=sample_image.shape[1:], linspace=100, in_channels=sample_image.shape[1] + 1 - 10,\n",
    "              train_image_folder=trn, val_image_folder=val, n_jobs=3, drop_rate=0.3, bn_momentum=0.9, bn_track_running_stats=False,\n",
    "              channels=[30, 30], batch_size=16, seq_len=sample_image.shape[0], epoch_size=None, lr=1e-4, \n",
    "              hierarchy_weights=weights1, kernel_size=3, stratified_input=True, reader=partial(reader, with_cloud_mask=True), reg_invariance=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4b808bf1f447d682b20482f7a7a153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=157.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=157.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=157.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=157.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(check_val_every_n_epoch=1, reload_dataloaders_every_epoch=False, \n",
    "                  checkpoint_callback=checkpoint_callback, default_save_path=default_save_path, nb_gpu_nodes=12,)\n",
    "                  #resume_from_checkpoint=os.path.join(default_save_path, 'checkpoints/epoch=24-val_loss=2.42.ckpt'))\n",
    "                 #train_percent_check=0.25)#,  val_check_interval=100, test_percent_check=0.1, check_val_every_n_epoch=0.25,)\n",
    "trainer.fit(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
